{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Четвёртое домашнее задание посвящено достаточно простой, но, надеюсь, интересной задаче, в которой потребуется творчески применить методы сэмплирования. Как и раньше, в качестве решения ожидается ссылка на jupyter-ноутбук на вашем github (или публичный, или с доступом для snikolenko); ссылку обязательно нужно прислать в виде сданного домашнего задания на портале Академии. Как всегда, любые комментарии, новые идеи и рассуждения на тему категорически приветствуются. \n",
    "В этом небольшом домашнем задании мы попробуем улучшить метод Шерлока Холмса. Как известно, в рассказе The Adventure of the Dancing Men великий сыщик расшифровал загадочные письмена из пляшущих человечков.\n",
    "\n",
    "Пользовался он для этого так называемым частотным методом: смотрел, какие буквы чаще встречаются в зашифрованных текстах, и пытался подставить буквы в соответствии с частотной таблицей: E — самая частая и так далее.\n",
    "В этом задании мы будем разрабатывать более современный и продвинутый вариант такого частотного метода"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import editdistance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 1*: Реализуйте базовый частотный метод по Шерлоку Холмсу:\n",
    "* подсчитайте частоты букв по корпусам (пунктуацию и капитализацию можно просто опустить, а вот пробелы лучше оставить);\n",
    "* возьмите какие-нибудь тестовые тексты (нужно взять по меньшей мере 2-3 предложения, иначе совсем вряд ли сработает), зашифруйте их посредством случайной перестановки символов;\n",
    "* расшифруйте их таким частотным методом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(path):\n",
    "    \"загружает данные для обучения\"\n",
    "    L = []\n",
    "    with open(path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line != '\\n':\n",
    "                L.append(line)\n",
    "                \n",
    "    text = ' '.join(L)\n",
    "    return preproc_text(text)\n",
    "\n",
    "def preproc_text(text):\n",
    "    \"удаление лишних символов\"\n",
    "    a = ord('а')\n",
    "    abc = ''.join([chr(i) for i in range(a,a+32)]) + 'ё '\n",
    "    \n",
    "    text = text.lower()\n",
    "    clear_text = ''\n",
    "    for t in text:\n",
    "        if t in abc:\n",
    "            clear_text += t\n",
    "            \n",
    "    text = ' '.join(clear_text.split())\n",
    "    return text\n",
    "\n",
    "\n",
    "def top_symbols(text, n):\n",
    "    \"возвращает отстортированный словарь и список ngramm по колличеству вхождений\"\n",
    "    counter = defaultdict(int)\n",
    "    for n_gramm in zip(*[text[i:] for i in range(n)]):\n",
    "        key = ''\n",
    "        for c in n_gramm:\n",
    "            key += c\n",
    "        counter[key] += 1\n",
    "        \n",
    "    counter = {k: v for k, v in sorted(counter.items(), key=lambda item: -item[1])}\n",
    "    list_counter = list(counter.keys())\n",
    "    \n",
    "    return counter, list_counter\n",
    "\n",
    "\n",
    "def encode(text, map_orig_to_code):\n",
    "    encode_text = ''\n",
    "    for t in text:\n",
    "        encode_text += map_orig_to_code[t]\n",
    "    return encode_text\n",
    "\n",
    "\n",
    "def decode_text(train_text, decode_text, n=1):\n",
    "    ngrams = []\n",
    "    _, train_list_counter = top_symbols(train_text, n)\n",
    "    _, test_list_counter = top_symbols(decode_text, n)\n",
    "    for i in range(0,len(decode_text), n):\n",
    "        ngrams.append(decode_text[i:i+n])\n",
    "    ngrams[-1] = decode_text[-n:]\n",
    "    encode_text = [train_list_counter[test_list_counter.index(n_gram)] for n_gram in ngrams]\n",
    "    return ''.join(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = get_text(\"data/WarAndPeace.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = ord('а')\n",
    "orig = ''.join([chr(i) for i in range(a,a+32)]) + 'ё '\n",
    "code = ''.join([chr(i) for i in range(1200,1200+34)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "абвгдежзийклмнопрстуфхцчшщъыьэюяё \n",
      "ҰұҲҳҴҵҶҷҸҹҺһҼҽҾҿӀӁӂӃӄӅӆӇӈӉӊӋӌӍӎӏӐӑ\n"
     ]
    }
   ],
   "source": [
    "print(orig)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "русское слово пельмени является заимствованием из пермских языков коми удм пельнянь хлебное ухо пель ухо нянь хлеб форма пельмень образовалась под влиянием севернорусского наречия через которое слово попало в литературный язык уральские диалектные формы пермяни пермени образовались в результате народноэтимологического сближения со словом пермьнекоторые популярные или устаревшие этимологические словари указывают в качестве источника угрофинские языки в целом мансийскийнеавторитетный источник и финскийнеавторитетный источник языкив в похлёбкин считал что пельмени пришли в русскую кухню с урала в конце начале веков в русских письменных документах уральских населённых пунктов веков с года встречаются фамилии образованные от слова пельмени пельменев пелненев пельменников историк п а корчагин на основе анализа упоминаний пельменных фамилий в документах отметил что в верхнем прикамье в году ещё не было людей которые зарабатывали изготовлением пельменейпельмени в традиционной культуре не были обрядовым блюдом и готовились по праздникам при встрече гостей и в заговенье\n",
      "ӀӃӁӁҺҾҵӑӁһҾҲҾӑҿҵһӌҼҵҽҸӑӏҲһӏҵӂӁӏӑҷҰҸҼӁӂҲҾҲҰҽҸҵҼӑҸҷӑҿҵӀҼӁҺҸӅӑӏҷӋҺҾҲӑҺҾҼҸӑӃҴҼӑҿҵһӌҽӏҽӌӑӅһҵұҽҾҵӑӃӅҾӑҿҵһӌӑӃӅҾӑҽӏҽӌӑӅһҵұӑӄҾӀҼҰӑҿҵһӌҼҵҽӌӑҾұӀҰҷҾҲҰһҰӁӌӑҿҾҴӑҲһҸӏҽҸҵҼӑӁҵҲҵӀҽҾӀӃӁӁҺҾҳҾӑҽҰӀҵӇҸӏӑӇҵӀҵҷӑҺҾӂҾӀҾҵӑӁһҾҲҾӑҿҾҿҰһҾӑҲӑһҸӂҵӀҰӂӃӀҽӋҹӑӏҷӋҺӑӃӀҰһӌӁҺҸҵӑҴҸҰһҵҺӂҽӋҵӑӄҾӀҼӋӑҿҵӀҼӏҽҸӑҿҵӀҼҵҽҸӑҾұӀҰҷҾҲҰһҸӁӌӑҲӑӀҵҷӃһӌӂҰӂҵӑҽҰӀҾҴҽҾӍӂҸҼҾһҾҳҸӇҵӁҺҾҳҾӑӁұһҸҶҵҽҸӏӑӁҾӑӁһҾҲҾҼӑҿҵӀҼӌҽҵҺҾӂҾӀӋҵӑҿҾҿӃһӏӀҽӋҵӑҸһҸӑӃӁӂҰӀҵҲӈҸҵӑӍӂҸҼҾһҾҳҸӇҵӁҺҸҵӑӁһҾҲҰӀҸӑӃҺҰҷӋҲҰӎӂӑҲӑҺҰӇҵӁӂҲҵӑҸӁӂҾӇҽҸҺҰӑӃҳӀҾӄҸҽӁҺҸҵӑӏҷӋҺҸӑҲӑӆҵһҾҼӑҼҰҽӁҸҹӁҺҸҹҽҵҰҲӂҾӀҸӂҵӂҽӋҹӑҸӁӂҾӇҽҸҺӑҸӑӄҸҽӁҺҸҹҽҵҰҲӂҾӀҸӂҵӂҽӋҹӑҸӁӂҾӇҽҸҺӑӏҷӋҺҸҲӑҲӑҿҾӅһӐұҺҸҽӑӁӇҸӂҰһӑӇӂҾӑҿҵһӌҼҵҽҸӑҿӀҸӈһҸӑҲӑӀӃӁӁҺӃӎӑҺӃӅҽӎӑӁӑӃӀҰһҰӑҲӑҺҾҽӆҵӑҽҰӇҰһҵӑҲҵҺҾҲӑҲӑӀӃӁӁҺҸӅӑҿҸӁӌҼҵҽҽӋӅӑҴҾҺӃҼҵҽӂҰӅӑӃӀҰһӌӁҺҸӅӑҽҰӁҵһӐҽҽӋӅӑҿӃҽҺӂҾҲӑҲҵҺҾҲӑӁӑҳҾҴҰӑҲӁӂӀҵӇҰӎӂӁӏӑӄҰҼҸһҸҸӑҾұӀҰҷҾҲҰҽҽӋҵӑҾӂӑӁһҾҲҰӑҿҵһӌҼҵҽҸӑҿҵһӌҼҵҽҵҲӑҿҵһҽҵҽҵҲӑҿҵһӌҼҵҽҽҸҺҾҲӑҸӁӂҾӀҸҺӑҿӑҰӑҺҾӀӇҰҳҸҽӑҽҰӑҾӁҽҾҲҵӑҰҽҰһҸҷҰӑӃҿҾҼҸҽҰҽҸҹӑҿҵһӌҼҵҽҽӋӅӑӄҰҼҸһҸҹӑҲӑҴҾҺӃҼҵҽӂҰӅӑҾӂҼҵӂҸһӑӇӂҾӑҲӑҲҵӀӅҽҵҼӑҿӀҸҺҰҼӌҵӑҲӑҳҾҴӃӑҵӉӐӑҽҵӑұӋһҾӑһӎҴҵҹӑҺҾӂҾӀӋҵӑҷҰӀҰұҰӂӋҲҰһҸӑҸҷҳҾӂҾҲһҵҽҸҵҼӑҿҵһӌҼҵҽҵҹҿҵһӌҼҵҽҸӑҲӑӂӀҰҴҸӆҸҾҽҽҾҹӑҺӃһӌӂӃӀҵӑҽҵӑұӋһҸӑҾұӀӏҴҾҲӋҼӑұһӎҴҾҼӑҸӑҳҾӂҾҲҸһҸӁӌӑҿҾӑҿӀҰҷҴҽҸҺҰҼӑҿӀҸӑҲӁӂӀҵӇҵӑҳҾӁӂҵҹӑҸӑҲӑҷҰҳҾҲҵҽӌҵ\n"
     ]
    }
   ],
   "source": [
    "map_orig_to_code = {}\n",
    "for o, c in zip(orig, code):\n",
    "    map_orig_to_code[o] = c\n",
    "\n",
    "test_text = '''Русское слово пельмени является заимствованием из пермских языков: коми, удм. пельнянь «хлебное ухо»: пель «ухо» + нянь «хлеб»[1][2][3][4][5]. Форма пельмень образовалась под влиянием севернорусского наречия, через которое слово попало в литературный язык. Уральские диалектные формы пермяни, пермени образовались в результате народно-этимологического сближения со словом Пермь.\n",
    "\n",
    "Некоторые популярные или устаревшие этимологические словари указывают в качестве источника «угро-финские языки» в целом[6], мансийский[7][неавторитетный источник?] и финский[8][неавторитетный источник?] языки.\n",
    "\n",
    "В. В. Похлёбкин считал, что пельмени пришли в русскую кухню с Урала в конце XIV — начале XV веков[9]. В русских письменных документах уральских населённых пунктов XVII—XVIII веков (с 1679 года) встречаются фамилии, образованные от слова «пельмени»: Пельменев, Пелненев, Пельменников[10]. Историк П. А. Корчагин на основе анализа упоминаний «пельменных» фамилий в документах отметил, что в верхнем Прикамье в 1579 году ещё не было людей, которые зарабатывали изготовлением пельменей[11].\n",
    "\n",
    "Пельмени в традиционной культуре не были обрядовым блюдом и готовились по праздникам — при встрече гостей и в заговенье'''\n",
    "test_text = preproc_text(test_text)\n",
    "encode_text = encode(test_text, map_orig_to_code)\n",
    "print(test_text)\n",
    "print(encode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'вуллкао лтаса мотпдоие ьстьорль гнедлрсасниеод ег мовдлкеы ьгякас каде убд мотпиьип ыточиао уыа мотп уыа иьип ыточ шавдн мотпдоип ачвнгаснтнлп маб стеьиеод лосовиавуллкайа инвозеь зовог каравао лтаса мамнта с теровнрувияж ьгяк увнтплкео бентокрияо шавдя мовдьие мовдоие ачвнгаснтелп с вогутпрнро инвабиаэредатайезолкайа лчтефоиеь ла лтасад мовдпиокаравяо мамутьвияо ете улрнвосщео эредатайезолкео лтаснве укнгяснхр с кнзолрсо елразиекн уйвашеилкео ьгяке с юотад днилежлкежионсраверорияж елразиек е шеилкежионсраверорияж елразиек ьгякес с маытцчкеи лзернт зра мотпдоие мвещте с вуллкух куыих л увнтн с каиюо инзнто сокас с вуллкеы мелпдоиияы бакудоирны увнтплкеы инлотциияы муикрас сокас л йабн слрвознхрль шндетее ачвнгасниияо ар лтасн мотпдоие мотпдоиос мотиоиос мотпдоииекас елравек м н кавзнйеи ин алиасо нинтегн умадеиниеж мотпдоиияы шндетеж с бакудоирны ардорет зра с совыиод мвекндпо с йабу оёц ио чята тхбож каравяо гнвнчнряснте егйарастоиеод мотпдоиожмотпдоие с рвнбеюеаииаж кутпруво ио чяте ачвьбасяд чтхбад е йарасетелп ма мвнгбиекнд мве слрвозо йалрож е с гнйасоипо'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#попытка декодировать текст, используя униграммы\n",
    "decode_text(train_text, encode_text, n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 2*: Вряд ли в результате получилась такая уж хорошая расшифровка, разве что если вы брали в качестве тестовых данных целые рассказы. Но и Шерлок Холмс был не так уж прост: после буквы E, которая действительно выделяется частотой, дальше он анализировал уже конкретные слова и пытался угадать, какими они могли бы быть. Я не знаю, как запрограммировать такой интуитивный анализ, так что давайте просто сделаем следующий логический шаг:\n",
    "* подсчитайте частоты биграмм (т.е. пар последовательных букв) по корпусам;\n",
    "* проведите тестирование аналогично п.1, но при помощи биграмм.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ве зсти тае на н о кторивилуие е ух кода дтоемл хо нпрь обрианста стлей пао я боойоснышек и сяна н ой этолойоснышетькаадо я ра восбы бс  дтвдоо ми сгоойниовдрлачеказаь есналилобе есклохост иими тае наваз но стуавротрт воотасжей  б оь ниаяндилсввои чапржи нпрой п нпр в пбы бс  дгодо сдишимесптри лиимихд ар жноамскь есназьгоцето еывалнодаов нпрботиоркатео удмерявои од пзан лоебниехар жноамскь ниално делй  ран д я с тязсекни в  инурееньнимку лнеи асже па знноовад лакь акм ым иелогмаисл ковыточт пку лнеыйулеекаавазвоотв  инурерианнеа а ваныахнеутагавпонн ио я ра в пю епго сдизаь вл тсяьеалй  бтв с тшазнолязпои ласта а ве знееречдо к мкиаялсгр вн ерт поиднеерлидрры мкио тнсве  стие алнямиенев э аияие еочлего пбы бс  д мтеу тытае ен н о ктоо я ра вльо я м м а  н о к мрее л кокарео ош ткаивамутлиу аее и  гпоруеных чы  гако я ра ввоерочлегоота егде квнжау г азоднн и с сроятемо ел рдни а онлютсвуоли угнотуажпе торкатеинатоитрожпо пруон иви вниов н о км айя ра в па  эушзвсс мби тмеспт и м солы пбыоюегаповсиаж чл няоре одв освао  бядто ровю  пев э аи онкопел  синр е  ввш'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#попытка декодировать текст, используя биграммы\n",
    "decode_text(train_text, encode_text, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gramm = 1, levenshtein dist = 849 \n",
      "n_gramm = 2, levenshtein dist = 895 \n",
      "n_gramm = 3, levenshtein dist = 882 \n",
      "n_gramm = 4, levenshtein dist = 868 \n",
      "n_gramm = 5, levenshtein dist = 883 \n"
     ]
    }
   ],
   "source": [
    "for n in range(1,6):\n",
    "    levenshtein = editdistance.eval(test_text, decode_text(train_text, encode_text, n=n))\n",
    "    print(\"n_gramm = {}, levenshtein dist = {} \".format(n, levenshtein))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина текста:  1076\n"
     ]
    }
   ],
   "source": [
    "print(\"Длина текста: \", len(test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем вывод, что н-граммы ухудшают качество. Видимо, слишком маленький тестовый датасет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 3*: Но и это ещё не всё: биграммы скорее всего тоже далеко не всегда работают. Основная часть задания — в том, как можно их улучшить:\n",
    "* предложите метод обучения перестановки символов в этом задании, основанный на MCMC-сэмплировании, но по-прежнему работающий на основе статистики биграмм;\n",
    "* реализуйте и протестируйте его, убедитесь, что результаты улучшились.\n",
    "\n",
    "*ANS*:\n",
    "\n",
    "Алгоритм решения задачи:\n",
    "\n",
    "1) Вычислим матрицу переходных вероятностей $P$ из одного символа в другой. Эта задача уже решена. В пункте 2 мы составили словарь, где каждой биграмме сопоставили сколько раз она встречается в обучающем тексте. Осталось лишь нормировать, чтобы получить вероятности. $P_{a,b}$ - вероятность перехода из символа $a$ в символ $b$.\n",
    "\n",
    "2) Нам потребуется начальное приближение для функции отображения $f$: закодированного символа в исходный. В качестве такой функции возьмем функцию отображения из пункта 1 на основе униграмм.\n",
    "\n",
    "3) При помощи $f$ декодируем сообщение и вычислим его правдоподобие: $L(f) = \\prod\\limits_{k}P_{f(x_k),f(x_{k+1})}$\n",
    "\n",
    "4) Случайно выбираются два аргумента у функции $f$ и значения функции при этих аргументах меняются местами. Если в результате такой перестановки правдоподобие увеличилось, то изменяем функцию $f$ (чтобы она давала значения, как с перестановкой), если уменьшилось, то изменяем функцию $f$ c вероятностью $\\dfrac{L(f_{new})}{L(f)}$\n",
    "\n",
    "5) Повторяем процедуру до сходимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deode_symbol(symbol, train_list_counter, encode_list_counter):\n",
    "    return train_list_counter[encode_list_counter.index(symbol)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mcmc_decode(encode_text, train_list_counter, encode_list_counter):\n",
    "    ans = []\n",
    "    for s in encode_text:\n",
    "        ans.append(deode_symbol(s, train_list_counter, encode_list_counter))\n",
    "    return ''.join(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(text):\n",
    "    p = 1\n",
    "    for bi_gramm in zip(*[text[i:] for i in range(2)]):\n",
    "        try:\n",
    "            p *= P[bi_gramm[0]+bi_gramm[1]]\n",
    "        except KeyError:\n",
    "            p *= min(P.values())\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bi_gramm_counter, train_bi_gramm_list_counter = top_symbols(train_text, 2)\n",
    "train_counter, train_list_counter = top_symbols(train_text, 1)\n",
    "\n",
    "_, encode_list_counter = top_symbols(encode_text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = sum(train_counter.values())\n",
    "P = train_bi_gramm_counter.copy()\n",
    "\n",
    "for k, v in P.items():\n",
    "    P[k] = P[k]/(N/600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отнормировали матрицу переходных вероятностей не в единицу, т.к иначе при вычисления правдоподобия быстро упремся в ноль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "599.9990661376868"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(P.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.5417300693003717e-295"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text = mcmc_decode(encode_text, train_list_counter, encode_list_counter)\n",
    "likelihood(decode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C * likelihood: 4.809668649820734e-141\n",
      "C * likelihood: 1.8099500550286027e+171\n",
      "C * likelihood: 1.701741214290345e+247\n",
      "C * likelihood: 5.375790680396495e+261\n",
      "C * likelihood: 3.176232707530327e+287\n",
      "C * likelihood: 5.456334119723607e+302\n",
      "C * likelihood: 5.456334119723607e+302\n",
      "C * likelihood: 6.2382398030900456e+302\n",
      "C * likelihood: 6.2382398030900456e+302\n",
      "C * likelihood: 6.2382398030900456e+302\n"
     ]
    }
   ],
   "source": [
    "L = likelihood(decode_text)\n",
    "for j in range(100):\n",
    "    for i in range(100):\n",
    "        test_list = encode_list_counter.copy()\n",
    "        idx_0, idx_1 = np.random.randint(0, len(test_list), 2)\n",
    "        test_list[idx_0], test_list[idx_1] = test_list[idx_1], test_list[idx_0]\n",
    "        decode_text = mcmc_decode(encode_text, train_list_counter, test_list)\n",
    "        L_NEW = likelihood(decode_text)\n",
    "        if L_NEW > L:\n",
    "            encode_list_counter = test_list\n",
    "            L = L_NEW\n",
    "        else:\n",
    "            p_change = L_NEW/L\n",
    "            if np.random.uniform(0,1) < p_change:\n",
    "                encode_list_counter = test_list\n",
    "                L = L_NEW\n",
    "    if j % 10 == 0: \n",
    "        print(\"C * likelihood:\", L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "русское слово пельмени является заимствованием из пермских языков коми удм пельнянь хлебное ухо пель ухо нянь хлеб жорма пельмень образовалась под влиянием севернорусского наречия через которое слово попало в литературный язык уральские диалектные жормы пермяни пермени образовались в результате народноэтимологического сблищения со словом пермьнекоторые популярные или устаревшие этимологические словари указывают в качестве источника угрожинские языки в целом мансийскийнеавторитетный источник и жинскийнеавторитетный источник языкив в похлёбкин считал что пельмени пришли в русскую кухню с урала в конце начале веков в русских письменных документах уральских населённых пунктов веков с года встречаются жамилии образованные от слова пельмени пельменев пелненев пельменников историк п а корчагин на основе анализа упоминаний пельменных жамилий в документах отметил что в верхнем прикамье в году ефё не было людей которые зарабатывали изготовлением пельменейпельмени в традиционной культуре не были обрядовым блюдом и готовились по праздникам при встрече гостей и в заговенье\n"
     ]
    }
   ],
   "source": [
    "mcmc_text = mcmc_decode(encode_text, train_list_counter, encode_list_counter)\n",
    "print(mcmc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "levenshtein dist = 8\n"
     ]
    }
   ],
   "source": [
    "levenshtein = editdistance.eval(test_text,mcmc_text)\n",
    "print(\"levenshtein dist =\", levenshtein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TASK 4*: Расшифруйте сообщение:\n",
    "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏\n"
     ]
    }
   ],
   "source": [
    "target_text = '←⇠⇒↟↹↷⇊↹↷↟↤↟↨←↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↟⇒↟↹⇷⇛⇞↨↟↹↝⇛⇯↳⇴⇒⇈↝⇊↾↹↨←⇌⇠↨↹⇙↹⇸↨⇛↙⇛↹⇠⇛⇛↲⇆←↝↟↞↹⇌⇛↨⇛⇯⇊↾↹⇒←↙⇌⇛↹⇷⇯⇛⇞↟↨⇴↨⇈↹⇠⇌⇛⇯←←↹↷⇠←↙⇛↹↷⇊↹↷⇠←↹⇠↤←⇒⇴⇒↟↹⇷⇯⇴↷↟⇒⇈↝⇛↹↟↹⇷⇛⇒⇙⇞↟↨←↹↳⇴⇌⇠↟↳⇴⇒⇈↝⇊↾↹↲⇴⇒⇒↹⇰⇴↹⇷⇛⇠⇒←↤↝←←↹⇞←↨↷←⇯↨⇛←↹⇰⇴↤⇴↝↟←↹⇌⇙⇯⇠⇴↹↘⇛↨↞↹⇌⇛↝←⇞↝⇛↹↞↹↝↟⇞←↙⇛↹↝←↹⇛↲←⇆⇴⇏'\n",
    "print(target_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.14704031136894e-44"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, encode_list_counter = top_symbols(target_text, 1)\n",
    "\n",
    "decode_text = mcmc_decode(target_text, train_list_counter, encode_list_counter)\n",
    "likelihood(decode_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C * likelihood: 0.0008895775616458849\n",
      "C * likelihood: 2.4444106864068064e+55\n",
      "C * likelihood: 7.082304640843486e+66\n",
      "C * likelihood: 1.411698307322235e+72\n",
      "C * likelihood: 5.015908432239445e+72\n",
      "C * likelihood: 9.522416467312183e+72\n",
      "C * likelihood: 4.798979600042083e+71\n",
      "C * likelihood: 3.502890118761377e+73\n",
      "C * likelihood: 2.585291482305958e+73\n",
      "C * likelihood: 2.585291482305958e+73\n",
      "C * likelihood: 2.585291482305958e+73\n",
      "C * likelihood: 3.502890118761377e+73\n",
      "C * likelihood: 1.9099526081343283e+72\n",
      "C * likelihood: 1.2198710355580712e+73\n",
      "C * likelihood: 7.693326662954124e+72\n",
      "C * likelihood: 9.522416467312183e+72\n",
      "C * likelihood: 3.502890118761377e+73\n",
      "C * likelihood: 2.585291482305958e+73\n",
      "C * likelihood: 4.110409980355971e+72\n",
      "C * likelihood: 5.015908432239445e+72\n",
      "C * likelihood: 5.08103741105339e+79\n",
      "C * likelihood: 2.6162402780177816e+85\n",
      "C * likelihood: 5.013413227447225e+88\n",
      "C * likelihood: 8.868392863670773e+89\n",
      "C * likelihood: 1.0486260297264497e+89\n",
      "C * likelihood: 3.408509405209821e+90\n",
      "C * likelihood: 1.2016055421239265e+90\n",
      "C * likelihood: 6.548384954226152e+90\n",
      "C * likelihood: 9.723303672846494e+89\n",
      "C * likelihood: 1.380397876912242e+89\n",
      "C * likelihood: 6.548384954226152e+90\n",
      "C * likelihood: 1.0045894369040392e+89\n",
      "C * likelihood: 1.2016055421239265e+90\n",
      "C * likelihood: 1.7833172320940576e+89\n",
      "C * likelihood: 1.921215728241157e+88\n",
      "C * likelihood: 1.3839820413394448e+87\n",
      "C * likelihood: 4.3853266271900055e+89\n",
      "C * likelihood: 1.0177265421229859e+86\n",
      "C * likelihood: 1.5125526210015408e+89\n",
      "C * likelihood: 6.9231494548753e+89\n",
      "C * likelihood: 3.408509405209821e+90\n",
      "C * likelihood: 6.944905678655064e+87\n",
      "C * likelihood: 8.868392863670773e+89\n",
      "C * likelihood: 6.548384954226152e+90\n",
      "C * likelihood: 3.408509405209821e+90\n",
      "C * likelihood: 1.8429734051950693e+88\n",
      "C * likelihood: 1.5186540776432117e+90\n",
      "C * likelihood: 6.548384954226152e+90\n",
      "C * likelihood: 7.684591233743256e+88\n",
      "C * likelihood: 2.5156342431216827e+90\n"
     ]
    }
   ],
   "source": [
    "L = likelihood(decode_text)\n",
    "for j in range(500):\n",
    "    for i in range(100):\n",
    "        test_list = encode_list_counter.copy()\n",
    "        idx_0, idx_1 = np.random.randint(0, len(test_list), 2)\n",
    "        test_list[idx_0], test_list[idx_1] = test_list[idx_1], test_list[idx_0]\n",
    "        decode_text = mcmc_decode(target_text, train_list_counter, test_list)\n",
    "        L_NEW = likelihood(decode_text)\n",
    "        if L_NEW > L:\n",
    "            encode_list_counter = test_list\n",
    "            L = L_NEW\n",
    "        else:\n",
    "            p_change = L_NEW/L\n",
    "            if np.random.uniform(0,1) < p_change:\n",
    "                encode_list_counter = test_list\n",
    "                L = L_NEW\n",
    "    if j % 10 == 0: \n",
    "        print(\"C * likelihood:\", L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_text = mcmc_decode(target_text, train_list_counter, encode_list_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "если вы вимите норшальный или подти норшальный текст у чтого соожбения который легко продитать скорее всего вы все смелали правильно и полудите шаксишальный жалл за послемнее детвертое замание курса хотя конедно я нидего не ожебаю\n"
     ]
    }
   ],
   "source": [
    "print(decode_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Бонус*: какие вы можете придумать применения для этой модели? Пляшущие человечки ведь не так часто встречаются в жизни (хотя встречаются! и это самое потрясающее во всей этой истории, но об этом я расскажу потом).\n",
    "\n",
    "*ANS*:\n",
    "Можем применить такую модель, когда у нас есть файл в неизвестной кодировке, но нам нужно его как-то прочитать."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
